{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mdevice:\u001b[0m\n",
      "device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from boring_transformer.boring_transformer import *\n",
    "from boring_transformer.boring_gpt import *\n",
    "from boring_transformer.utils import *\n",
    "\n",
    "device = get_device()\n",
    "cprint(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 11706\n",
    "\n",
    "# batch_size=32\n",
    "# block_size=1024\n",
    "batch_size = 64  # how many independent sequences will we process in parallel?\n",
    "block_size = 256  # what is the maximum context length for predictions?\n",
    "# max_iters = 5000\n",
    "max_iters = 4000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_embed = n_embd\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'shakespeare'\n",
    "data_dir = os.path.join('./data', dataset)\n",
    "train_data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "val_data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mvocab_size:\u001b[0m\n",
      "11706\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "\n",
    "# meta_path = os.path.join(data_dir, 'meta.pkl')\n",
    "# meta_vocab_size = None\n",
    "# if os.path.exists(meta_path):\n",
    "#     with open(meta_path, 'rb') as f:\n",
    "#         meta = pickle.load(f)\n",
    "#     meta_vocab_size = meta['vocab_size']\n",
    "#     print(f\"found vocab_size = {meta_vocab_size} (inside {meta_path})\")\n",
    "# else:\n",
    "#     all_data = np.concatenate((train_data, val_data))\n",
    "#     unique_tokens = np.unique(all_data)\n",
    "#     vocab_size = len(unique_tokens)\n",
    "\n",
    "#     # 11706\n",
    "#     cprint(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_batch_np(train_data, block_size=block_size, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape  # block_size=1024, batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = BoringTransformerModel(\n",
    "#     vocab_size, n_embd, n_head, n_layer, n_embd * 4, block_size, dropout\n",
    "# ).to(device)\n",
    "m = BoringGPT(\n",
    "    vocab_size, n_embd, n_head, n_layer, n_embd * 4, block_size, dropout\n",
    ").to(device)\n",
    "\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(max_iters):\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss(m, train_data, val_data, block_size, batch_size, eval_iters, device)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(train_data, block_size, batch_size, device)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
