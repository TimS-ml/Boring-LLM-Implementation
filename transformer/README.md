# Ref:
- paper: Attention Is All You Need http://arxiv.org/abs/1706.03762v7
- [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)
- [lucidrains/x-transformers: A simple but complete full-attention transformer with a set of promising experimental features from various papers](https://github.com/lucidrains/x-transformers)


