- [x] autoregressive masking in basic attention

- [ ] flash attention
- [ ] sliding window attention 

- [ ] EvoFormer
- [ ] GraphFormer
- [ ] DiT

- [ ] RoPE
- [ ] LoRA
- [ ] PEFT Adapter

- [ ] Simple training setup
